{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import open\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import sys\n",
    "import torch.quantization\n",
    "from torch.quantization import QuantStub, DeQuantStub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite, create_mobilenetv2_ssd_lite_predictor\n",
    "from vision.utils.misc import Timer\n",
    "import torch.quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post training Quantization : Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [name.strip() for name in open('models/voc-model-labels.txt').readlines()]\n",
    "num_classes = len(class_names)\n",
    "model = create_mobilenetv2_ssd_lite(len(class_names), is_test=True)\n",
    "model.load_state_dict(torch.load('models/mb2-ssd-lite-mp-0_686.pth',map_location=torch.device('cpu')))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fuse_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "print(model.qconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.prepare(model, inplace=True)\n",
    "# evaluate(per_channel_quantized_model,criterion, data_loader, num_calibration_batches)\n",
    "torch.quantization.convertert(model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"test.jpg\")\n",
    "if image.shape[2] == 1:\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "else:\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = cv2.transform(image, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = create_mobilenetv2_ssd_lite_predictor(model, candidate_size=200, device='cpu')\n",
    "boxes, labels, probs = predictor.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'new_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./test.pth') #Save to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('./test.pth') #Reload to the model  OKKKKKKKKKKKKKK!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you recreate a empty model  NOT okkkkkkkkkkkkkkkk!!!\n",
    "model_load = create_mobilenetv2_ssd_lite(len(class_names), is_test=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then you reload you quantized model to this empty file\n",
    "#This is the problem\n",
    "# It is not working because the keys are different now\n",
    "model_load.load('./test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"readme_ssd_example.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = create_mobilenetv2_ssd_lite_predictor(model, candidate_size=200, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pytorch/pytorch/issues/28483\n",
    "#Check out this issue feels like you didn't do the fuse properly\n",
    "predictor.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uninplace(model):\n",
    "    \"\"\"Sets all `inplace` values to False\"\"\"\n",
    "    if hasattr(model, 'inplace'):\n",
    "        model.inplace = False\n",
    "    if not model.children():\n",
    "        return\n",
    "    for child in model.children():\n",
    "        uninplace(child)\n",
    "\n",
    "def prep_for_fusion(model, parent_name):\n",
    "    \"\"\"Fuses all conv+bn+relu, conv+bn, and conv+relu\"\"\"\n",
    "    if not model.children():\n",
    "        return []\n",
    "    result = []\n",
    "    candidate = []\n",
    "    for name, child in model.named_children():\n",
    "        new_name = parent_name + '.' + name\n",
    "        if new_name[0] == '.':\n",
    "            new_name = new_name[1:]\n",
    "        if type(child) == torch.nn.Sequential:\n",
    "            candidate = []\n",
    "            result.extend(prep_for_fusion(child, new_name))\n",
    "        else:\n",
    "            if len(candidate) == 0 and type(child) == torch.nn.Conv2d:\n",
    "                candidate = [new_name]\n",
    "            elif len(candidate) == 1 and type(child) == torch.nn.ReLU:\n",
    "                candidate.append(new_name)\n",
    "                result.append(candidate)\n",
    "                candidate = []\n",
    "            elif len(candidate) == 1 and type(child) == torch.nn.BatchNorm2d:\n",
    "                candidate.append(new_name)\n",
    "            elif len(candidate) == 2:\n",
    "                if type(child) == torch.nn.ReLU:\n",
    "                    candidate.append(new_name)\n",
    "                result.append(candidate)\n",
    "                candidate = []\n",
    "    return result\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# example = torch.rand(1, 3, 224, 224)\n",
    "# traced_script_module = torch.jit.trace(model, example)\n",
    "# traced_script_module.save('vgg16_bn_float32.pt')\n",
    "\n",
    "uninplace(model)  # This is a hack!\n",
    "\n",
    "modules_to_fuse = prep_for_fusion(model, '')\n",
    "\n",
    "model.qconfig = torch.quantization.default_qconfig\n",
    "fused_model = torch.quantization.fuse_modules(model, modules_to_fuse,inplace=True)\n",
    "\n",
    "torch.quantization.prepare(fused_model, inplace=True)\n",
    "quantized = torch.quantization.convert(fused_model, inplace=True)\n",
    "\n",
    "q_example = torch.quantize_per_tensor(example, scale=1e-3, zero_point=128,\n",
    "                                      dtype=torch.quint8)\n",
    "\n",
    "\n",
    "# traced_script_module = torch.jit.trace(quantized, q_example, check_trace=False)\n",
    "# traced_script_module.save('vgg16_bn_qint8.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "navya",
   "language": "python",
   "name": "navya"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
